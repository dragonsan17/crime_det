{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPEEKtoDUJC7KitNjzloJAy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dragonsan17/crime_det/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Huc-ZYgrtSdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AZhJ4Lxq6_C",
        "colab_type": "code",
        "outputId": "43dfa807-ede5-4bc9-dadb-32dcaaee8cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vG1eb0wslZg",
        "colab_type": "code",
        "outputId": "6801675d-3783-49e1-8b52-9406c0ce8753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#my data\n",
        "data_path_1 = '/content/gdrive/My Drive/crime_det/final_tweet_data_25k.csv'\n",
        "\n",
        "with open(data_path_1, newline='') as f_1:\n",
        "    reader = csv.reader(f_1)\n",
        "    train_data = list(reader)\n",
        "#sourav's data\n",
        "data_path_2 = '/content/gdrive/My Drive/crime_det/final_tweet_data_2.csv'\n",
        "\n",
        "with open(data_path_2, newline='') as f_2:\n",
        "    reader = csv.reader(f_2)\n",
        "    valid_data = list(reader)\n",
        "print(len(train_data))\n",
        "print(len(valid_data))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "464\n",
            "415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arfI2kh5vg4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# crimes = ['hostage','murder','robbery','con','fraud','kidnap','rape','terrorism','terror','crime','protest','pelt','arson','clash']\n",
        "# # crimes = ['murder']\n",
        "# crime_index = {}\n",
        "# for i in range(len(crimes)):\n",
        "#   crime_index[crimes[i]] = i\n",
        "\n",
        "# # crime_index['theft'] = crime_index['robbery']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDVleUH6EWUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new_train_data = []\n",
        "# new_valid_data = []\n",
        "# # for i in range(len(train_data)):\n",
        "# #   if(train_data[i][0]!='murder'):\n",
        "# #     continue\n",
        "# #   else:\n",
        "# #     new_train_data.append(train_data[i])\n",
        "# for i in range(len(valid_data)):\n",
        "#   if(valid_data[i][1]!='-1'):\n",
        "#     continue\n",
        "#   else:\n",
        "#     new_valid_data.append(valid_data[i])\n",
        "# # train_data = new_train_data\n",
        "# valid_data = new_valid_data\n",
        "\n",
        "# # print(len(valid_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwxoQULcuWCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_prep(data):\n",
        "  token_list = []\n",
        "  label_list = []\n",
        "\n",
        "  for crime,num,s_token,tweet in data:\n",
        "    token_list.append(s_token[1:-1].split(', '))\n",
        "    label_list.append(max(int(num),0))\n",
        "\n",
        "  for i in range(len(token_list)):\n",
        "    for j in range(len(token_list[i])):\n",
        "      token_list[i][j] = token_list[i][j][1:-1]\n",
        "  # print(len(token_list))\n",
        "  tokens = {}\n",
        "  crime_info = {}\n",
        "  # print(len(data))\n",
        "  for i in range(len(data)):\n",
        "    tokens[data[i][3]] = token_list[i]\n",
        "    crime_info[data[i][3]] = []\n",
        "  for i in range(len(data)):\n",
        "    crime_info[data[i][3]].append(max(int(data[i][1]),0))\n",
        "\n",
        "  x = []\n",
        "  y = []\n",
        "\n",
        "  for tweet in tokens:\n",
        "    x.append(tokens[tweet])\n",
        "    label = 0\n",
        "    for num in crime_info[tweet]:\n",
        "      label = max(num,0)\n",
        "    y.append(label)\n",
        "  return x,y \n",
        "\n",
        "x_train,y_train = data_prep(train_data)\n",
        "x_valid,y_valid = data_prep(valid_data)\n",
        "\n",
        "training_labels_final = np.array(y_train).astype(int)\n",
        "testing_labels_final = np.array(y_valid).astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL8uee1x918k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 5000\n",
        "embedding_dim = 16\n",
        "trunc_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(x_train)\n",
        "final_x_train = pad_sequences(sequences,truncating=trunc_type)\n",
        "max_length = len(final_x_train[0])\n",
        "testing_sequences = tokenizer.texts_to_sequences(x_valid)\n",
        "final_x_valid = pad_sequences(testing_sequences,maxlen = max_length)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iogjrVee_LQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    # tf.keras.layers.Flatten(),\n",
        "    # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
        "    # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8)),\n",
        "    # tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X0CImTCAnk2",
        "colab_type": "code",
        "outputId": "ef3fc3bc-bcf3-4625-933d-8dd82220a6ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        }
      },
      "source": [
        "model.fit(final_x_train, training_labels_final, epochs=15, shuffle=True, validation_data=(final_x_valid, testing_labels_final),verbose = 2)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "13/13 - 1s - loss: 0.6898 - accuracy: 0.5652 - val_loss: 0.6843 - val_accuracy: 0.6031\n",
            "Epoch 2/15\n",
            "13/13 - 0s - loss: 0.6809 - accuracy: 0.5652 - val_loss: 0.6781 - val_accuracy: 0.6031\n",
            "Epoch 3/15\n",
            "13/13 - 0s - loss: 0.6694 - accuracy: 0.5652 - val_loss: 0.6699 - val_accuracy: 0.6031\n",
            "Epoch 4/15\n",
            "13/13 - 0s - loss: 0.6490 - accuracy: 0.5652 - val_loss: 0.6590 - val_accuracy: 0.6031\n",
            "Epoch 5/15\n",
            "13/13 - 0s - loss: 0.6105 - accuracy: 0.5831 - val_loss: 0.6465 - val_accuracy: 0.6031\n",
            "Epoch 6/15\n",
            "13/13 - 0s - loss: 0.5415 - accuracy: 0.7545 - val_loss: 0.6297 - val_accuracy: 0.6186\n",
            "Epoch 7/15\n",
            "13/13 - 0s - loss: 0.4223 - accuracy: 0.8798 - val_loss: 0.6332 - val_accuracy: 0.6546\n",
            "Epoch 8/15\n",
            "13/13 - 0s - loss: 0.2835 - accuracy: 0.9488 - val_loss: 0.6278 - val_accuracy: 0.7036\n",
            "Epoch 9/15\n",
            "13/13 - 0s - loss: 0.1869 - accuracy: 0.9744 - val_loss: 0.6677 - val_accuracy: 0.7139\n",
            "Epoch 10/15\n",
            "13/13 - 0s - loss: 0.1231 - accuracy: 0.9821 - val_loss: 0.7632 - val_accuracy: 0.7113\n",
            "Epoch 11/15\n",
            "13/13 - 0s - loss: 0.0933 - accuracy: 0.9872 - val_loss: 0.6934 - val_accuracy: 0.7242\n",
            "Epoch 12/15\n",
            "13/13 - 0s - loss: 0.0572 - accuracy: 1.0000 - val_loss: 1.0602 - val_accuracy: 0.6778\n",
            "Epoch 13/15\n",
            "13/13 - 0s - loss: 0.0509 - accuracy: 1.0000 - val_loss: 0.7705 - val_accuracy: 0.7242\n",
            "Epoch 14/15\n",
            "13/13 - 0s - loss: 0.0339 - accuracy: 0.9974 - val_loss: 0.9531 - val_accuracy: 0.7165\n",
            "Epoch 15/15\n",
            "13/13 - 0s - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.9177 - val_accuracy: 0.7294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5bc144c8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}