{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMef1QAiAj+z4iG4rz28NC8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dragonsan17/crime_det/blob/master/model3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIo9m8J3aqSG",
        "colab_type": "code",
        "outputId": "f42be947-5b67-44a2-f667-b56183924d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJiGpXFxcume",
        "colab_type": "code",
        "outputId": "2e7f7db7-8516-457b-f0bb-3e1be7c5f0d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwxR8gnKdBRS",
        "colab_type": "code",
        "outputId": "7d7a842d-2929-4cb3-89b4-660338327658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "file1_path = \"/content/gdrive/My Drive/f.csv\"\n",
        "file2_path = \"/content/gdrive/My Drive/out.csv\"\n",
        "with open(file1_path) as csvfile:\n",
        "  readCSV = csv.reader(csvfile, delimiter=',')\n",
        "  file1 = list(readCSV)\n",
        "with open(file2_path) as csvfile:\n",
        "  readCSV = csv.reader(csvfile, delimiter=',')\n",
        "  file2 = list(readCSV)\n",
        "print(file1[0:2])\n",
        "print(file2[0:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['murder', '1', \"['shock', 'journalist', 'safe', 'pakistan', 'murder', 'journalist', 'req']\", '@abbasz55 @jamilnagri Shocking, journalists are no where safe in Pakistan, murder of journalist #AliSherRajjpur reqâ€¦ https://t.co/XAdshoUERH'], ['murder', '1', \"['brutal', 'murder', 'girl', 'report', 'bahu', 'plaza', 'area', 'more', 'detail', 'await']\", 'Brutal Murder of a girl has been reported in Bahu Plaza area. More details awaited https://t.co/V499wUiYYe']]\n",
            "[['murder', '1', \"['murder']\", '@Ndlotus1 @t_d_h_nair @ameytirodkar Murdered'], ['murder', '1', \"['look', 'paid', 'analyst', 'wz', 'tweet', 'zainab', 'murder', 'case', 'hous', 'km', 'away', 'rm', 'Fa']\", 'Look at this ðŸ‘‡ðŸ‘‡how these paid analyst wz tweeting during Zainab murder case, now his house is just 3km away 4rm  Faâ€¦ https://t.co/WMVsurZHV9']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yTw4qwseTRm",
        "colab_type": "code",
        "outputId": "dabe745c-e757-4a79-f860-70d23f405235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# prepare Data by santosh\n",
        "def data_prep(data):\n",
        "  token_list = []\n",
        "  label_list = []\n",
        "\n",
        "  for crime,num,s_token,tweet in data:\n",
        "    token_list.append(s_token[1:-1].split(', '))\n",
        "    label_list.append(max(int(num),0))\n",
        "\n",
        "  for i in range(len(token_list)):\n",
        "    for j in range(len(token_list[i])):\n",
        "      token_list[i][j] = token_list[i][j][1:-1]\n",
        "  # print(len(token_list))\n",
        "  tokens = {}\n",
        "  crime_info = {}\n",
        "  # print(len(data))\n",
        "  for i in range(len(data)):\n",
        "    tokens[data[i][3]] = token_list[i]\n",
        "    crime_info[data[i][3]] = []\n",
        "  for i in range(len(data)):\n",
        "    crime_info[data[i][3]].append(max(int(data[i][1]),0))\n",
        "\n",
        "  x = []\n",
        "  y = []\n",
        "\n",
        "  for tweet in tokens:\n",
        "    x.append(tokens[tweet])\n",
        "    label = 0\n",
        "    for num in crime_info[tweet]:\n",
        "      label = max(num,0)\n",
        "    y.append(label)\n",
        "  return x,y\n",
        "\n",
        "x_train,y_train = data_prep(file1)\n",
        "x_valid,y_valid = data_prep(file2)\n",
        "\n",
        "training_labels_final = np.array(y_train).astype(int)\n",
        "testing_labels_final = np.array(y_valid).astype(int)\n",
        "\n",
        "# print(x_train[0:2])\n",
        "# print(x_valid[0:2])\n",
        "# print(y_train[0:2])\n",
        "# print(y_valid[0:2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['shock', 'journalist', 'safe', 'pakistan', 'murder', 'journalist', 'req'], ['brutal', 'murder', 'girl', 'report', 'bahu', 'plaza', 'area', 'more', 'detail', 'await']]\n",
            "[['murder'], ['look', 'paid', 'analyst', 'wz', 'tweet', 'zainab', 'murder', 'case', 'hous', 'km', 'away', 'rm', 'Fa']]\n",
            "[1, 1]\n",
            "[1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVK8l44pfznF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 64\n",
        "max_length = 100\n",
        "trunc_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(x_train)\n",
        "x_train_padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(x_valid)\n",
        "x_valid_padded = pad_sequences(testing_sequences,maxlen=max_length)\n",
        "\n",
        "# print(x_train_padded[0:2])\n",
        "# print(x_valid_padded[0:2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7MVJgrIg9BY",
        "colab_type": "code",
        "outputId": "f8ac090a-b779-4e4b-b77b-d69e2131faca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dense(6, activation='relu'),\n",
        "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "# ])\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    # tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    # tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n",
        "            # tf.keras.layers.Conv1D(256, 6, activation='relu'),\n",
        "            # tf.keras.layers.GlobalMaxPool1D(),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    # tf.keras.layers.Dense(16, activation='relu'),\n",
        "    # tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_31 (Embedding)     (None, 100, 64)           640000    \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 666,945\n",
            "Trainable params: 666,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OsXfYpLjwkK",
        "colab_type": "code",
        "outputId": "6a47af48-c79f-4606-95d8-2b7f0eb5bd66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "num_epochs = 10\n",
        "model.fit(x_train_padded, training_labels_final, epochs=num_epochs, validation_data=(x_valid_padded, testing_labels_final))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "13/13 [==============================] - 2s 117ms/step - loss: 0.6859 - accuracy: 0.5678 - val_loss: 0.6709 - val_accuracy: 0.6031\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.6388 - accuracy: 0.5934 - val_loss: 0.6408 - val_accuracy: 0.6186\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 1s 52ms/step - loss: 0.4902 - accuracy: 0.8338 - val_loss: 0.5903 - val_accuracy: 0.7268\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.2674 - accuracy: 0.9233 - val_loss: 0.5745 - val_accuracy: 0.7242\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.1087 - accuracy: 0.9719 - val_loss: 0.7044 - val_accuracy: 0.7320\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.0599 - accuracy: 0.9795 - val_loss: 0.8273 - val_accuracy: 0.7113\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 1s 53ms/step - loss: 0.0266 - accuracy: 0.9949 - val_loss: 0.7303 - val_accuracy: 0.7345\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.0195 - accuracy: 0.9949 - val_loss: 0.8433 - val_accuracy: 0.7216\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.9248 - val_accuracy: 0.7139\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 1s 54ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 0.7575 - val_accuracy: 0.7397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0b2d20c978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs9qKoHGkJAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}